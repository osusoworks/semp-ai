---
title: "【Gemini 3 Flash】画面の「ここ」を教えてくれるAI先輩『SENP_AI』を作った話【Cloud Run】"
emoji: "📍"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["gch4", "python", "gemini", "cloudrun", "ai"]
published: false
---

## はじめに

**「Agentic AI Hackathon with Google Cloud」**の参加作品です。  
PC操作に迷う人のために、画面上の操作すべき場所を**赤い矢印**で物理的（視覚的）に教えてくれるAIアシスタント**「SENP_AI（センパイ）」**を開発しました。

## 解決する課題

新しいソフトウェアやWebサービスの使い方がわからないとき、マニュアルを読んだり人に聞いたりするのは大変です。

- 「設定画面の『詳細』タブを開いてください」と言われても、「詳細タブってどこ？」となる
- スクリーンショット付きのマニュアルを探すのが面倒
- そもそも機能の名前がわからなくて検索できない

こうした「場所がわからない」という問題に対し、言葉での説明だけでなく、画面上に直接**「赤い枠」や「矢印」**を表示して、直感的に操作を誘導します。

## ソリューション: SENP_AI

SENP_AI は常駐型のデスクトップアシスタントです。
ユーザーが「ダークモードの設定はどこ？」と質問すると、**Gemini 3 Flash** のマルチモーダル機能を使って画面を解析し、該当するボタンやメニューの正確な位置を特定して、画面上にオーバーレイで**赤い枠（や矢印）**を表示します。

![Demo](https://dummyimage.com/600x400/000/fff&text=Demo+Video+Placeholder)
*(※ 実際のデモでは、AIが画面を認識し、操作対象に矢印を表示します)*

## 主な機能

### 1. 🎯 Visual Grounding (座標特定)

Gemini API に独自のプロンプトを与え、ターゲット要素のバウンディングボックスを出力させています。
単に「右上にあります」とテキストで返すだけでなく、`[TARGET_BOX: y_min, x_min, y_max, x_max]` という形式で座標を受け取り、Python (Tkinter) で実際の画面上に枠や矢印を描画します。

### 2. ⚡ 高速レスポンス

最新の **Gemini 3 Flash** モデルを採用。
以前のモデルに比べ、画像認識と推論の速度が格段に向上しており、ユーザーを待たせないリアルタイムなガイドを実現しました。
Cloud Run 上のサーバーレス構成により、スケーラビリティも確保しています。

### 3. 📜 自動スクロール解析

Webページなど、一画面に収まらない長いコンテンツの場合でも大丈夫です。
「ページ全体を見て」や「下の方も確認して」と指示すると、Pythonスクリプトが自動でスクロールしながら複数枚のスクリーンショットを撮影。それらを統合して Gemini に渡し、ページ全体の構造を理解させます。

### 4. 🗣️ 音声対話 (Voice Interaction)

キーボード入力すら面倒な時、マイクボタン一つで質問可能です。
回答も音声合成 (TTS) で読み上げられるため、ハンズフリーに近い感覚で操作ガイドを受けられます。

## 技術スタック

### Backend (Google Cloud)

- **Google Cloud Run**: ステートレスなコンテナとしてバックエンドをデプロイ
- **Python (Flask)**: APIサーバーの実装
- **Google GenAI SDK**: Gemini 3 Flash との通信

### Frontend (Desktop Client)

- **Python (CustomTkinter)**: モダンなUIフレームワーク
- **PyAutoGUI**: スクリーンショット撮影、自動スクロール操作
- **SpeechRecognition / pyttsx3**: 音声認識と音声合成

## システム構成図

```mermaid
graph LR
    User[Desktop Client] -- 画像 + 質問/音声 --> CloudRun[Cloud Run (Python/Flask)]
    CloudRun -- マルチモーダル解析 --> Gemini[Gemini 3 Flash]
    Gemini -- 座標データ + 回答 --> CloudRun
    CloudRun -- レスポンス --> User
    User -- 赤い矢印を描画/音声ガイド --> Screen[画面オーバーレイ]
```

## こだわりポイント

### UI/UX: 親しみやすい「先輩」

無機質なAIではなく、頼れる「センパイ」として振る舞うようなシステムプロンプトを設定しています。
また、画面の邪魔にならないよう、必要時以外はコンパクトなUIに収まるよう設計しました。

### 精度への挑戦: Visual Grounding

LLMにとって「正確な座標」を出力するのは難しい課題ですが、Gemini 3 Flash の高い視覚認識能力と、独自の座標変換ロジック（0-1000スケールとDPIスケーリングの調整）を組み合わせることで、ボタン一つを正確に指し示せる精度を実現しました。

## 今後の展望

現在は「ガイド（可視化）」に特化していますが、将来的には「代わりにクリックしてくれる」真のアジェンティックな機能へと進化させたいと考えています。
Cloud Run の並列処理能力を活かし、より複雑なタスク（「この資料を整理しておいて」など）にも対応できるようにしていきたいです。

---

*This project was built for the Agentic AI Hackathon with Google Cloud.*
