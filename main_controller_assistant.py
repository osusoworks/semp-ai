"""
Main Controller for SENPAI Assistant
ã‚·ãƒ³ãƒ—ãƒ«ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç‰ˆã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
"""

import os
import time
from datetime import datetime
from ui_module_assistant import AssistantUI
from ai_module_improved import AIModule
from speech_module import SpeechModule
from tts_module import TTSModule
from PIL import ImageGrab

class AssistantController:
    def __init__(self):
        """ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–"""
        self.ai_module = AIModule()
        self.speech_module = SpeechModule()
        self.tts_module = TTSModule()
        
        self.ui = AssistantUI(
            on_screenshot_callback=self.take_screenshot,
            on_question_callback=self.process_question,
            on_voice_input_callback=self.handle_voice_input,
            on_tts_toggle_callback=self.toggle_tts
        )
        
        self.current_screenshot = None
        self.tts_enabled = True
        
        # èµ·å‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.ui.add_message(
            "assistant",
            "ã“ã‚“ã«ã¡ã¯ï¼SENPAIã§ã™ã€‚\nç”»é¢ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æ’®ã£ã¦ã€è³ªå•ã—ã¦ãã ã•ã„ã€‚",
            self._get_timestamp()
        )
        self.ui.set_status("æº–å‚™å®Œäº†", "green")
    
    def _get_timestamp(self):
        """ç¾åœ¨æ™‚åˆ»ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
        return datetime.now().strftime("%H:%M:%S")
    
    def take_screenshot(self):
        """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’æ’®å½±"""
        try:
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ’®å½±
            screenshot = ImageGrab.grab()
            
            # ä¿å­˜
            screenshot_dir = "screenshots"
            os.makedirs(screenshot_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            screenshot_path = os.path.join(screenshot_dir, f"screenshot_{timestamp}.png")
            screenshot.save(screenshot_path)
            
            self.current_screenshot = screenshot_path
            
            self.ui.set_status(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å®Œäº†: {screenshot_path}", "green")
            
        except Exception as e:
            error_msg = f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(error_msg)
            self.ui.set_status(error_msg, "red")
    
    def process_question(self, question):
        """è³ªå•ã‚’å‡¦ç†ã—ã¦AIå›ç­”ã‚’å–å¾—"""
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            self.ui.add_message("user", question, self._get_timestamp())
            
            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãŒãªã„å ´åˆ
            if not self.current_screenshot:
                answer = "ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãŒæ’®å½±ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã€ŒğŸ“¸ ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚"
                self.ui.add_message("assistant", answer, self._get_timestamp())
                self.ui.set_status("æº–å‚™å®Œäº†", "green")
                return
            
            # AIåˆ†æ
            self.ui.set_status("AIåˆ†æä¸­...", "blue")
            
            result = self.ai_module.analyze_screen(
                screenshot_path=self.current_screenshot,
                user_question=question
            )
            
            if result["success"]:
                answer = result["answer"]
                self.ui.add_message("assistant", answer, self._get_timestamp())
                
                # TTSéŸ³å£°å‡ºåŠ›
                if self.tts_enabled:
                    self.tts_module.speak(answer)
                
                self.ui.set_status("æº–å‚™å®Œäº†", "green")
            else:
                error_msg = f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                self.ui.add_message("assistant", error_msg, self._get_timestamp())
                self.ui.set_status(error_msg, "red")
        
        except Exception as e:
            error_msg = f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(error_msg)
            self.ui.add_message("assistant", error_msg, self._get_timestamp())
            self.ui.set_status(error_msg, "red")
    
    def handle_voice_input(self):
        """éŸ³å£°å…¥åŠ›ã‚’å‡¦ç†"""
        try:
            self.ui.set_status("éŸ³å£°å…¥åŠ›ä¸­...", "blue")
            
            # éŸ³å£°èªè­˜
            result = self.speech_module.listen()
            
            if result["success"]:
                recognized_text = result["text"]
                self.ui.set_input_text(recognized_text)
                self.ui.set_status("éŸ³å£°èªè­˜å®Œäº†", "green")
                
                # è‡ªå‹•çš„ã«è³ªå•ã‚’é€ä¿¡
                time.sleep(0.5)
                self.process_question(recognized_text)
            else:
                error_msg = f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                self.ui.set_status(error_msg, "red")
        
        except Exception as e:
            error_msg = f"éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(error_msg)
            self.ui.set_status(error_msg, "red")
    
    def toggle_tts(self, enabled):
        """TTS ON/OFFã‚’åˆ‡ã‚Šæ›¿ãˆ"""
        self.tts_enabled = enabled
        
        if not enabled and self.tts_module.is_speaking():
            self.tts_module.stop()
        
        status = "æœ‰åŠ¹" if enabled else "ç„¡åŠ¹"
        print(f"éŸ³å£°å›ç­”: {status}")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•"""
        try:
            self.ui.run()
        except KeyboardInterrupt:
            print("\nçµ‚äº†ã—ã¾ã™...")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
        self.tts_module.cleanup()
        print("å®Œäº†")


if __name__ == "__main__":
    controller = AssistantController()
    controller.run()

